{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb769187",
   "metadata": {},
   "source": [
    "**CPLN 680 Capstone Project**\n",
    "\n",
    "Rui Jiang\n",
    "\n",
    "This notebook aims to save scripts I used to do the analysis and data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f44f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#read file\n",
    "file = r'C:\\Users\\jrach\\Desktop\\Jiang_Rui_RecreationPhilly\\raw_data\\NE_CSO.xlsx'###\n",
    "data = pd.read_excel(file)\n",
    "print(\"raw:\",data)\n",
    "#convert date time to date(year,month,day)\n",
    "data[\"Date\"] = data[\"Datetime [EST\\EDT]\"].dt.date\n",
    "\n",
    "# use date to sum up daily volume for each CSO outfall\n",
    "data = data.groupby(['Date']).sum()\n",
    "\n",
    "#check\n",
    "print(\"check:\",data)\n",
    "\n",
    "#write the output excel file\n",
    "name = \"CSOdaily2019.xlsx\"###\n",
    "savefile=data.to_excel(name)\n",
    "print(\"Excel file created sucessfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f15595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plt.plot(x,y);\n",
    "#plt.plot(x, y, 'r--o')\n",
    "#plt.xlabel('x')\n",
    "#plt.ylabel('y')\n",
    "#plt.title('title');\n",
    "#plt.plot(x, y, 'r--o', x, y ** 1.1, 'bs', x, y ** 1.2, 'g^-' );\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4223a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e46e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "\n",
    "#comments\n",
    "###changable\n",
    "\n",
    "\n",
    "def universal_excelsheet(file, columnNameforDate, columnNameforBacteria, columnNameforLocation, columnforData):\n",
    "    exceldata = pd.read_excel(file)\n",
    "    exceldf = pd.DataFrame(exceldata)\n",
    "    exceldf.rename(columns={columnNameforDate: 'Date', columnNameforBacteria: 'Bacteria',\n",
    "                            columnNameforLocation: 'Location', columnforData: 'Data'}, inplace=True)\n",
    "    exceldf = exceldf.dropna(subset=['Date', 'Bacteria', 'Location', 'Data'])\n",
    "    exceldf.to_excel('data.xlsx')\n",
    "    return exceldf\n",
    "\n",
    "### FIT EXCEL SHEET\n",
    "#DRBC 2019\n",
    "#excel = '/Nearshore_Bacteria.xlsx'\n",
    "#PWD\n",
    "#excel = '/Howard_Neukrug_Water_Center_PWD_Shore_Grab_Bacteria_2019.xlsx'\n",
    "#DRBC 2020\n",
    "excel = 'DRBC 2020 nearshore.xlsx'\n",
    "\n",
    "\n",
    "### FIT THE COLUMNS NAMES OF ABOVE EXCEL SHEET\n",
    "#DRBC\n",
    "#ExcelSheet(excel,'ActivityStartDate','CharacteristicName','Location','ResultMeasureValue')\n",
    "#PWD\n",
    "#ExcelSheet(excel,'sample.date', 'parameter', 'loc.ID', 'data.value')\n",
    "#DRBC 2020\n",
    "universal_excelsheet(excel, 'CollectionDate', 'Parameter', 'SiteName', 'result')\n",
    "\n",
    "#Excel Sheet made from function\n",
    "data = pd.read_excel(r'/data.xlsx')\n",
    "\n",
    "#### Create a pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Geometric Mean\n",
    "def geo_mean(iterable):\n",
    "    a = np.array(iterable)\n",
    "    return a.prod()**(1.0/len(a))\n",
    "\n",
    "# Statistical Threshold Value\n",
    "def stv(iterable):\n",
    "    # log based 10 : STV = 10 ** ( avg(log values) + 1.282 * std(log values) )\n",
    "    b = np.log10(iterable)\n",
    "    eq = 10 ** (st.mean(b) + (1.282 * st.stdev(b)))\n",
    "    return eq\n",
    "\n",
    "# Average\n",
    "def average(iterable):\n",
    "    a = np.array(iterable)\n",
    "    eq = (a.sum())/(len(iterable))\n",
    "    return eq\n",
    "\n",
    "# Create a list of lists for the bacteria, location, month, etc\n",
    "LIST = []\n",
    "\n",
    "# month, bacteria, and location -> geometric mean, STV, average, and percentiles\n",
    "# exports into a new pandas dataframe\n",
    "def pullingdata(month,year,bacteria,locationID):\n",
    "    # Matching the correct columns with the parameters from the function\n",
    "    DATA = (df.loc[(df['Date'].dt.month == (month))\n",
    "                   & (df['Date'].dt.year == (year))\n",
    "                   & (df['Bacteria'] == (bacteria))\n",
    "                   & (df['Location'] == (locationID))])\n",
    "\n",
    "    # Make a list of all of the data (MPN/100mL) with the same criteria (month, bacteria, and location iD\n",
    "    DataList = DATA['Data'].tolist()\n",
    "    DayList = DATA['Date'].dt.day.tolist()\n",
    "\n",
    "    # If there is no data for the month, only print this statement and do nothing else\n",
    "    if not DataList:\n",
    "        print(\"No data for month \" + str(month) + \"\\n\")\n",
    "\n",
    "    elif len(DataList) == 1:\n",
    "        print(\"Bacteria: \" + str(bacteria))\n",
    "        print(\"Location ID: \" + str(locationID))\n",
    "        print(\"Month/Year: \" + str(month) + \"/\" + str(year))\n",
    "        print(DataList)\n",
    "        print(DayList)\n",
    "        print(average(DataList))\n",
    "        print(\"Only one data point - cannot calculate STV, GM, or percentiles\\n\")\n",
    "        x = 'NA'\n",
    "        return LIST.append([month, year, locationID, float(average(DataList)), bacteria,x,x,x,x,x,DataList[0],x,x,x,DataList,DayList])\n",
    "\n",
    "    # If there is data for the month, make a list of the month, location, bacteria, and the geometric mean\n",
    "    else:\n",
    "        print(\"Bacteria: \" + str(bacteria))\n",
    "        print(\"Location ID: \" + str(locationID))\n",
    "        print(\"Month/Year: \" + str(month) + \"/\" + str(year))\n",
    "        print(DataList)\n",
    "        print(DayList)\n",
    "        print(average(DataList))\n",
    "        print(\"Geometric Mean: \" + str(geo_mean(DataList)))\n",
    "        print(\"STV: \" + str(stv(DataList)) + \"\\n\")\n",
    "        p0 = np.percentile(DataList, 0)\n",
    "        p5 = np.percentile(DataList, 5)\n",
    "        p25 = np.percentile(DataList, 25)\n",
    "        p50 = np.percentile(DataList, 50)\n",
    "        p75 = np.percentile(DataList, 75)\n",
    "        p90 = np.percentile(DataList, 90)\n",
    "        p100 = np.percentile(DataList, 100)\n",
    "        return LIST.append([month, year, locationID, bacteria, float(average(DataList)), float(geo_mean(DataList)), float(stv(DataList)),\n",
    "                            float(p0),float(p5),float(p25),float(p50),float(p75),float(p90),float(p100),\n",
    "                            DataList,DayList])\n",
    "\n",
    "# Make a list of only the unique locations and bacteria types\n",
    "LocationList = df['Location'].unique().tolist()\n",
    "BacteriaList = df['Bacteria'].unique().tolist()\n",
    "YearList = df['Date'].dt.year.unique().tolist()\n",
    "\n",
    "i=0\n",
    "#loop through all the years\n",
    "for Y in range(len(YearList)):\n",
    "    # outer loop is for all the months\n",
    "    while i < 13:\n",
    "        # middle loop is running through all the unique locations\n",
    "        for L in range(len(LocationList)):\n",
    "            # inner loop is running through all of the unique bacteria\n",
    "            for B in range(len(BacteriaList)):\n",
    "                # running the above function\n",
    "                pullingdata(i,YearList[Y],BacteriaList[B],LocationList[L])\n",
    "        i+=1\n",
    "\n",
    "\n",
    "\n",
    "exportingdata = pd.DataFrame(columns = [\"MONTH\", \"YEAR\", \"LocationID\",\"Bacteria\",\"Average\",\"GEO MEAN\",\"STV\",\n",
    "                                   \"P0\",\"P5\",\"P25\",\"P50\",\"P75\",\"P90\",\"P100\",\n",
    "                                   \"Data List\",\"Day List\"])\n",
    "\n",
    "\n",
    "# make the earlier defined list into a dataframe\n",
    "exportingdata = exportingdata.append(pd.DataFrame(LIST, columns = exportingdata.columns))\n",
    "\n",
    "\n",
    "##### EXPORT TO EXCEL\n",
    "\n",
    "### CHANGE THIS TO NAME\n",
    "#file_name = 'PWDdata.xlsx'\n",
    "#file_name = 'DRBC2020data.xlsx'\n",
    "\n",
    "# saving the excel\n",
    "exportingdata.to_excel(file_name)\n",
    "print('Export to excel successfully.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e535d18",
   "metadata": {},
   "source": [
    "Rain Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ea421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# To make the important column names universal for all the bacterial data\n",
    "def universal_excelsheet(file, ColumnNameforDate, ColumnNameforBacteria, ColumnNameforLocation, ColumnforData):\n",
    "    data = pd.read_excel(file)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns={ColumnNameforDate: 'Date', ColumnNameforBacteria: 'Bacteria',\n",
    "                       ColumnNameforLocation: 'Location', ColumnforData: 'Data'}, inplace=True)\n",
    "    df = df.dropna(subset=['Date', 'Bacteria', 'Location', 'Data'])\n",
    "    df.to_excel('data.xlsx')\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "excel = 'raw_data/FIB and Field Data1.xlsx'\n",
    "\n",
    "universal_excelsheet(excel, 'Sample Date', 'Bacteria', 'Station', 'Result') \n",
    "\n",
    "\n",
    "# Excel Sheet made from function\n",
    "data = pd.read_excel(r'/data.xlsx')\n",
    "df = pd.DataFrame(data) # turn into pandas dataframe\n",
    "\n",
    "\n",
    "\n",
    "def RainExcelSheet(file1999,file2005,file2008,file2019, file2020, file2021): # creates a separate excel sheet of all the rainfall information\n",
    "    # read in two columns date and prcp from each year rainfall data file\n",
    "    data2005 = pd.read_excel(file2005, usecols=[\"DATE\", \"PRCP\"])\n",
    "    data1999 = pd.read_excel(file1999, usecols=[\"DATE\", \"PRCP\"]) \n",
    "    data2008 = pd.read_excel(file2008, usecols=[\"DATE\", \"PRCP\"])\n",
    "    data2019 = pd.read_excel(file2019, usecols=[\"DATE\", \"PRCP\"])\n",
    "    data2020 = pd.read_excel(file2020, usecols=[\"DATE\", \"PRCP\"])\n",
    "    data2021 = pd.read_excel(file2021, usecols=[\"DATE\", \"PRCP\"])\n",
    "    # turn into a pandas dataframe\n",
    "    df1999 = pd.DataFrame(data1999) \n",
    "    df2005 = pd.DataFrame(data2005)\n",
    "    df2008 = pd.DataFrame(data2008)\n",
    "    df2019 = pd.DataFrame(data2019)\n",
    "    df2020 = pd.DataFrame(data2020)\n",
    "    df2021 = pd.DataFrame(data2021)\n",
    "    # combine all the data frames\n",
    "    frames = [df1999, df2005, df2008, df2019, df2020, df2021]\n",
    "    df = pd.concat(frames)\n",
    "    # do the rolling sum of the rainfall\n",
    "    df['SumTwoDays'] = round(df['PRCP'].rolling(window=2).sum(), 4) \n",
    "    df['SumThreeDays'] = round(df['PRCP'].rolling(window=3).sum(), 4)\n",
    "    df['SumSixDays'] = round(df['PRCP'].rolling(window=6).sum(), 4)\n",
    "    df['SumTenDays'] = round(df['PRCP'].rolling(window=10).sum(), 4)\n",
    "    # count the number of days after a certain rainfall event amount\n",
    "    df['Count of days after .1 Rainfall Event'] = df.groupby((df['PRCP'] >= .1).cumsum()).cumcount()\n",
    "    df['Count of days after any rainfall event'] = df.groupby((df['PRCP'] > 0).cumsum()).cumcount()\n",
    "    # put all this into one excel sheet\n",
    "    df.to_excel('RainData.xlsx')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Excel sheet for the precipiation\n",
    "\n",
    "excel1999 = r\"RawData/rain1999to2004.xlsx\"\n",
    "excel2005 = r\"RawData/rain2005to2007.xlsx\"\n",
    "excel2008 = r\"RawData/rain2008to2018.xlsx\"\n",
    "excel2019 = r\"raw_data/Philadelphia Airport Precip data 2019.xlsx\"\n",
    "excel2020 = r\"RawData/RainData2020.xlsx\"\n",
    "excel2021 = r\"RawData/NOAARainfall2021.xlsx\"\n",
    "\n",
    "# combine all the rainfall datasheets I have into one complete excel file in using the RainExcelSheet function\n",
    "RainExcelSheet(excel1999, excel2005, excel2008, excel2019, excel2020, excel2021)\n",
    "raindata = pd.read_excel(r'RainData.xlsx')\n",
    "df1 = pd.DataFrame(raindata)\n",
    "\n",
    "# Function that gets a dataframe and turns it into a dictionary\n",
    "def dataframe_to_dict(df, key_column, value_column):\n",
    "    dict = df.set_index(key_column)[value_column].to_dict()\n",
    "    return dict\n",
    "\n",
    "# turns this information into a dictionary in order to add it into another dataset\n",
    "rain_dict = dataframe_to_dict(df1, 'DATE', 'PRCP')\n",
    "TwoDays_dict = dataframe_to_dict(df1, 'DATE', 'SumTwoDays')\n",
    "ThreeDays_dict = dataframe_to_dict(df1, 'DATE', 'SumThreeDays')\n",
    "SixDays_dict = dataframe_to_dict(df1, 'DATE', 'SumSixDays')\n",
    "TenDays_dict = dataframe_to_dict(df1, 'DATE', 'SumTenDays')\n",
    "Count_dict = dataframe_to_dict(df1, 'DATE', 'Count of days after .1 Rainfall Event')\n",
    "Count_dict2 = dataframe_to_dict(df1, 'DATE', 'Count of days after any rainfall event')\n",
    "\n",
    "DAILYLIST = (df['Date']) # makes a list of all the dates\n",
    "\n",
    "# make a list of lists for all of the rain values\n",
    "totalrain = []\n",
    "totaltwo = []\n",
    "totalthree = []\n",
    "totalsix = []\n",
    "totalten = []\n",
    "totalcount = []\n",
    "totalcount2 = []\n",
    "for DateInList in DAILYLIST:\n",
    "    print(DateInList)\n",
    "    rain = rain_dict.get(DateInList)\n",
    "    two = TwoDays_dict.get(DateInList)\n",
    "    print(two)\n",
    "    three = ThreeDays_dict.get(DateInList)\n",
    "    print(three)\n",
    "    six = SixDays_dict.get(DateInList)\n",
    "    print(six)\n",
    "    ten = TenDays_dict.get(DateInList)\n",
    "    print(ten)\n",
    "    count = Count_dict.get(DateInList)\n",
    "    print(count)\n",
    "    count2 = Count_dict2.get(DateInList)\n",
    "    print(count2)\n",
    "    totalrain.append(rain)\n",
    "    totaltwo.append(two)\n",
    "    totalthree.append(three)\n",
    "    totalsix.append(six)\n",
    "    totalten.append(ten)\n",
    "    totalcount.append(count)\n",
    "    totalcount2.append(count2)\n",
    "\n",
    "# This makes the excel sheet into separate columns with the following titles, so each rainfall amount is its own column    \n",
    "exportingrain = (pd.DataFrame({'Rain per Each Day': totalrain, 'Sum of Rain for Two Days': totaltwo,\n",
    "                               'Sum of Rain for Three Days': totalthree, 'Sum of Rain for Six Days': totalsix,\n",
    "                               'Sum of Rain for Ten Days': totalten,\n",
    "                               'Count of days after .1 Rainfall Event': totalcount,\n",
    "                               'Count of days after any rainfall event': totalcount2}))\n",
    "\n",
    "# join the two data\n",
    "exportingdata = pd.concat([df, exportingrain], axis=1)\n",
    "\n",
    "##### EXPORT TO EXCEL\n",
    "\n",
    "\n",
    "file_name = 'Summer2021Data_Rainfall.xlsx'\n",
    "\n",
    "# saving the excel\n",
    "exportingdata.to_excel(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5701a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "data = pd.read_excel(r'/Water Research/DRBC 2019,2020,2021/DRBC 19,20,21.xlsx')\n",
    "#print(data)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "Data = df.loc[(df['Bacteria'] == ('E.Coli'))]\n",
    "\n",
    "DataList = Data['Data'].tolist()\n",
    "\n",
    "LogData = np.log10(DataList).tolist()\n",
    "\n",
    "#plt.hist(LogData, bins=25)\n",
    "#plt.show()\n",
    "\n",
    "# list of distributions in scipy\n",
    "list_of_dists = ['alpha', 'anglit', 'arcsine', 'beta', 'betaprime', 'bradford', 'burr', 'burr12', 'cauchy', 'chi',\n",
    "                 'chi2', 'cosine', 'dgamma', 'dweibull', 'erlang', 'expon', 'exponnorm', 'exponweib', 'exponpow', 'f',\n",
    "                 'fatiguelife', 'fisk', 'foldcauchy', 'foldnorm', 'frechet_r', 'frechet_l', 'genlogistic', 'genpareto',\n",
    "                 'gennorm', 'genexpon', 'genextreme', 'gausshyper', 'gamma', 'gengamma', 'genhalflogistic', 'gilbrat',\n",
    "                 'gompertz', 'gumbel_r', 'gumbel_l', 'halfcauchy', 'halflogistic', 'halfnorm', 'halfgennorm',\n",
    "                 'hypsecant', 'invgamma', 'invgauss', 'invweibull', 'johnsonsb', 'johnsonsu', 'kstwobign', 'laplace',\n",
    "                 'levy', 'levy_l', 'logistic', 'loggamma', 'loglaplace', 'lognorm', 'lomax', 'maxwell', 'mielke',\n",
    "                 'nakagami', 'ncx2', 'ncf', 'nct', 'norm', 'pareto', 'pearson3', 'powerlaw', 'powerlognorm',\n",
    "                 'powernorm', 'rdist', 'reciprocal', 'rayleigh', 'rice', 'recipinvgauss', 'semicircular', 't', 'triang',\n",
    "                 'truncexpon', 'truncnorm', 'tukeylambda', 'uniform', 'vonmises', 'vonmises_line', 'wald',\n",
    "                 'weibull_min', 'weibull_max']\n",
    "\n",
    "results = []\n",
    "\n",
    "# fit every distribution to the dataset\n",
    "for i in list_of_dists:\n",
    "    dist = getattr(stats, i)\n",
    "    param = dist.fit(LogData)\n",
    "    a = stats.kstest(LogData, i, args=param)\n",
    "    results.append((i, a[0], a[1]))\n",
    "\n",
    "# sort the results, best fitting is on the top\n",
    "results.sort(key=lambda x: float(x[2]), reverse=True)\n",
    "for j in results:\n",
    "    print(\"{}: statistic= {}, pvalue= {}\".format(j[0], j[1], j[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5498aba",
   "metadata": {},
   "source": [
    "Wet and dry weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d97287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import gmean\n",
    "import statistics as st\n",
    "\n",
    "# Dictionary of Target Values for each bacteria\n",
    "targetGM = {\"Fecal Coliform\": 200, \"Fecal coliform\": 200, \"Fecal\\nColiform\":200,\n",
    "          \"Enterococci\": 35, \"Enterococcus\":35,\n",
    "          \"E.coli\": 126, \"E.Coli\": 126, \"Ecoli\": 126, \"Escherichia coli\":126, \"Escherichia\\nColi\":126,\n",
    "          \"Total Coliform\": 200}\n",
    "targetSTV = {\"Fecal Coliform\": 770, \"Fecal coliform\": 770, \"Fecal\\nColiform\":770,\n",
    "          \"Enterococci\": 130, \"Enterococcus\":130,\n",
    "          \"E.coli\": 410, \"E.Coli\": 410, \"Ecoli\": 410, \"Escherichia coli\":410, \"Escherichia\\nColi\":410,\n",
    "          \"Total Coliform\": 770}\n",
    "\n",
    "def target_number(iterable, targetvalue): # if the bacteria is greater than the target value, count it.\n",
    "    if len(iterable) < 1:\n",
    "        return \"NA\"\n",
    "    else:\n",
    "        count = 0\n",
    "        for i in iterable:\n",
    "            if i > targetvalue:\n",
    "                count = count + 1\n",
    "        return count\n",
    "\n",
    "def target_percentile(iterable, targetvalue): # calculate the percent of bacteria that is greater than the target value\n",
    "    if len(iterable) < 1:\n",
    "        return \"NA\"\n",
    "    else:\n",
    "        count = 0\n",
    "        for i in iterable:\n",
    "            if i >= targetvalue:\n",
    "                count += 1\n",
    "        totallist = len(iterable)\n",
    "        return round((count / totallist) * 100, 1)\n",
    "\n",
    "# Statistical Threshold Value\n",
    "def stv(iterable):\n",
    "    # log based 10 : STV = 10 ** ( avg(log values) + 1.282 * std(log values) )\n",
    "    print(\"STV LIST: \",iterable)\n",
    "    iterable = [i for i in iterable if i != 0]\n",
    "    print(\"NEW STV LIST: \", iterable)\n",
    "    if len(iterable) < 3:\n",
    "        print(\"THIS IS HITTING THE <3 MARK\")\n",
    "        return \"NA\"\n",
    "    else:\n",
    "        b = np.log10(iterable)\n",
    "        eq = 10 ** (st.mean(b) + (1.282 * st.stdev(b)))\n",
    "        return round(eq,1)\n",
    "\n",
    "def geomean(iterable): # Geometric mean\n",
    "    if len(iterable) < 5:\n",
    "        return \"NA\"\n",
    "    else:\n",
    "        return round(float(gmean(iterable)),1)\n",
    "\n",
    "def maxvalue(iterable): # max value of the list\n",
    "    if len(iterable) < 2:\n",
    "        return 'NA'\n",
    "    else:\n",
    "        return round(float(max(iterable)),2)\n",
    "\n",
    "def minvalue(iterable): # min value of the list\n",
    "    if len(iterable) < 2:\n",
    "        return 'NA'\n",
    "    else:\n",
    "        return round(float(min(iterable)),2)\n",
    "\n",
    "# Create a list of lists for the bacteria, location, month, etc\n",
    "LIST = []\n",
    "\n",
    "\n",
    "# Uses the month, bacteria, and location, get the geometric mean, STV, average, and percentiles\n",
    "# and exports this information into a new pandas dataframe\n",
    "def makingdatasheet(bacteria, locationID):\n",
    "    # ALL DATA FIRST\n",
    "    # Matching the correct columns with the parameters from the function\n",
    "    DATA = (df.loc[(df['Bacteria'] == (bacteria))\n",
    "                   & (df['Location'] == (locationID))])\n",
    "\n",
    "    # Make a list of all of the data (MPN/100mL) with the same criteria (bacteria and location)\n",
    "    DataList = DATA['Data'].tolist()\n",
    "\n",
    "\n",
    "    print(\"\\nBacteria: \" + str(bacteria))\n",
    "    print(\"Location ID: \" + str(locationID))\n",
    "    print(\"Data List for all values \",DataList)\n",
    "\n",
    "    if not DataList:\n",
    "        print(\"No data\\n\")\n",
    "\n",
    "    else:\n",
    "        # Print to check the loop\n",
    "        print(\"Length of total data \",len(DataList))\n",
    "\n",
    "        # Percentiles\n",
    "        p0 = round(np.percentile(DataList, 0),1)\n",
    "        p5 = round(np.percentile(DataList, 5),1)\n",
    "        p25 = round(np.percentile(DataList, 25),1)\n",
    "        p50 = round(np.percentile(DataList, 50),1)\n",
    "        p75 = round(np.percentile(DataList, 75),1)\n",
    "        p90 = round(np.percentile(DataList, 90),1)\n",
    "        p100 = round(np.percentile(DataList, 100),1)\n",
    "\n",
    "        # Target Value Caculations\n",
    "        #print(\"DATA LIST NOW \",DataList)\n",
    "        targetnumberGM = target_number(DataList, targetGM[str(bacteria)])\n",
    "        targetpercentGM = target_percentile(DataList, targetGM[str(bacteria)])\n",
    "        targetnumberSTV = target_number(DataList, targetSTV[str(bacteria)])\n",
    "        targetpercentSTV = target_percentile(DataList, targetSTV[str(bacteria)])\n",
    "        GM = geomean(DataList)\n",
    "        STV = stv(DataList)\n",
    "        print('scipy GM ',GM)\n",
    "        print(\"Target GM\",targetGM[str(bacteria)])\n",
    "        print(\"Target STV\", targetSTV[str(bacteria)])\n",
    "        print(\"Target Number GM \",targetnumberGM)\n",
    "        print(\"Target Percent GM \",targetpercentGM)\n",
    "        print(\"Target Number STV \",targetnumberSTV)\n",
    "        print(\"Target Percent STV \",targetpercentSTV)\n",
    "\n",
    "        # DRY WEATHER DATA\n",
    "        drydata = (df.loc[(df['Bacteria'] == (bacteria))\n",
    "                          & (df['Location'] == (locationID))\n",
    "                          & (df['Sum of Rain for Two Days'] < .1)])\n",
    "        DryDataList = drydata['Data'].tolist()\n",
    "        print(\"Length of dry data \", len(DryDataList))\n",
    "        drytargetnumberGM = target_number(DryDataList, targetGM[str(bacteria)])\n",
    "        drytargetpercentGM = target_percentile(DryDataList, targetGM[str(bacteria)])\n",
    "        drytargetnumberSTV = target_number(DryDataList, targetSTV[str(bacteria)])\n",
    "        drytargetpercentSTV = target_percentile(DryDataList, targetSTV[str(bacteria)])\n",
    "        drySTV = stv(DryDataList)\n",
    "        dryGM = geomean(DryDataList)\n",
    "        drymin = minvalue(DryDataList)\n",
    "        drymax = maxvalue(DryDataList)\n",
    "\n",
    "        # WET WEATHER DATA\n",
    "        wetdata = (df.loc[(df['Bacteria'] == (bacteria))\n",
    "                          & (df['Location'] == (locationID))\n",
    "                          & (df['Sum of Rain for Two Days'] >=.1)])\n",
    "        WetDataList = wetdata['Data'].tolist()\n",
    "        print(\"Length of wet data \", len(WetDataList))\n",
    "        wettargetpercentGM = target_percentile(WetDataList, targetGM[str(bacteria)])\n",
    "        wettargetnumberGM = target_number(WetDataList, targetGM[str(bacteria)])\n",
    "        wettargetpercentSTV = target_percentile(WetDataList, targetSTV[str(bacteria)])\n",
    "        wettargetnumberSTV = target_number(WetDataList, targetSTV[str(bacteria)])\n",
    "        wetSTV = stv(WetDataList)\n",
    "        wetGM = geomean(WetDataList)\n",
    "        wetmin = minvalue(WetDataList)\n",
    "        wetmax = maxvalue(WetDataList)\n",
    "\n",
    "        return LIST.append([locationID, bacteria, targetGM[str(bacteria)], targetSTV[str(bacteria)],\n",
    "                            len(DataList),\n",
    "                            float(p0), float(p5), float(p25), float(p50), float(p75), float(p90), float(p100),\n",
    "                            targetnumberGM, targetpercentGM,\n",
    "                            targetnumberSTV, targetpercentSTV,\n",
    "                            GM, STV,\n",
    "                            len(DryDataList), len(WetDataList),\n",
    "                            drytargetnumberGM, wettargetnumberGM,\n",
    "                            drytargetnumberSTV, wettargetnumberSTV,\n",
    "                            drytargetpercentGM, wettargetpercentGM,\n",
    "                            drytargetpercentSTV, wettargetpercentSTV,\n",
    "                            dryGM, wetGM,\n",
    "                            drySTV, wetSTV,\n",
    "                            drymin, drymax, wetmin, wetmax])\n",
    "\n",
    "\n",
    "\n",
    "#### Create a Pandas Dataframe of the data.\n",
    "exportingdata = pd.DataFrame(columns=[\"Location\", \"Bacteria\", \"Target Value for GM\", \"Target Value for STV\",\n",
    "                                      \"Number of Observations\",\n",
    "                                      \"P0\", \"P5\", \"P25\", \"P50\", \"P75\", \"P90\", \"P100\",\n",
    "                                      \"Number Exceeding Target GM\", \"Percent that exceed the Target GM\",\n",
    "                                      \"Number Exceeding Target STV\", \"Percent that exceed the Target STV\",\n",
    "                                      \"Geo Mean\", \"STV\",\n",
    "                                      \"Number of Dry Weather Samples\", \"Number of Wet Weather Samples\",\n",
    "                                      \"Number Dry Samples Exceeding Target GM\", \"Number Wet Samples Exceeding Target GM\",\n",
    "                                      \"Number Dry Samples Exceeding Target STV\", \"Number Wet Samples Exceeding Target STV\",\n",
    "                                      \"Percent of Dry Samples that exceed the Target GM\", \"Percent of Wet Samples that exceed the Target GM\",\n",
    "                                      \"Percent of Dry Samples that exceed the Target STV\", \"Percent of Wet Samples that exceed the Target STV\",\n",
    "                                      \"Dry Samples GM\", \"Wet Samples GM\", \"Dry Samples STV\", \"Wet Samples STV\",\n",
    "                                      \"Low of Dry Samples\", \"High of Dry Samples\",\n",
    "                                      \"Low of Wet Samples\",\"High of Wet Samples\"])\n",
    "\n",
    "\n",
    "AllData = pd.read_excel(r'/All Data.xlsx')\n",
    "#### Create a pandas dataframe\n",
    "df = pd.DataFrame(AllData)\n",
    "\n",
    "# Make a list of only the unique locations and bacteria types\n",
    "LocationList = df['Location'].unique().tolist()\n",
    "BacteriaList = df['Bacteria'].unique().tolist()\n",
    "\n",
    "print('Location List:\\n', LocationList)\n",
    "print('BacteriaList:\\n', BacteriaList)\n",
    "\n",
    "for L in range(len(LocationList)): #loops through all the unique location\n",
    "    for B in range(len(BacteriaList)): #loops through all the unique bacteria\n",
    "        makingdatasheet(BacteriaList[B], LocationList[L]) # runs it through the function\n",
    "\n",
    "\n",
    "exportingdata = exportingdata.append(pd.DataFrame(LIST, columns=exportingdata.columns))\n",
    "\n",
    "##### EXPORT TO EXCEL\n",
    "\n",
    "### CHANGE THIS TO NAME\n",
    "file_name = 'AllData_WetandDryData.xlsx'\n",
    "\n",
    "# saving the excel\n",
    "exportingdata.to_excel(file_name)\n",
    "print('\\nDataFrame is written to Excel File successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7651597f",
   "metadata": {},
   "source": [
    "**Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d488c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee5a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exceldata = pd.read_excel('AllDataYearly.xlsx')\n",
    "df = pd.DataFrame(exceldata)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f858651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ecolidf = df[df['Bacteria']==\"E.coli\"]\n",
    "Ecolidf2019 = Ecolidf[Ecolidf['Year']==2019]\n",
    "EColidf = df[df['Bacteria']==\"E.Coli\"]\n",
    "Ecolidf2020 = EColidf[EColidf['Year']==2020]\n",
    "Ecolidf2021 = EColidf[EColidf['Year']==2021]\n",
    "#Ecolidf2019.loc[:,['Location','Number of Observations','P0', 'P5', 'P25', 'P50', 'P75', 'P90', 'P100', 'GeoMean', 'STV','Number Exceeding Target GM', 'Percent that Exceed the Target STV']]\n",
    "#temp = Ecolidf2019.loc[:,['Location','GeoMean']]\n",
    "temp = Ecolidf2021.loc[:,['Location','Dry Samples GM']]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a93ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "plt.axhline(y=10, color=\"red\", linestyle=\":\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Nearshore | E.coli | 2021 | Dry\")\n",
    "plt.ylabel(\"cfu/100mL\")\n",
    "ax.set_ylim([-100, 2000])\n",
    "plt.plot(temp['Location'],temp['Dry Samples GM'],'o', color='black')\n",
    "\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
